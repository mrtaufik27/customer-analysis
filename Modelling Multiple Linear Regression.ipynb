{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:32:02.134592Z",
     "start_time": "2021-11-22T06:32:02.132274Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import broadcast\n",
    "# startTime = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:36:00.828695Z",
     "start_time": "2021-11-22T06:36:00.823072Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy \n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:36:01.441241Z",
     "start_time": "2021-11-22T06:36:01.438187Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np \n",
    "import scipy \n",
    "import scipy.stats as ss\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:36:02.646921Z",
     "start_time": "2021-11-22T06:36:02.644298Z"
    }
   },
   "outputs": [],
   "source": [
    "# LOG_REFRESSION\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konfigurasi Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:36:06.275110Z",
     "start_time": "2021-11-22T06:36:06.269465Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import os\n",
    "conf = SparkConf()\n",
    "conf = conf.set(\"spark.executor.cores\", 4)\n",
    "conf = conf.set(\"spark.executor.memory\", \"16g\")\n",
    "conf = conf.set(\"spark.executor.instances\", 10)\n",
    "conf = conf.set('spark.yarn.executor.memoryOverhead', '10g')\n",
    "conf = conf.set('spark.io.compression.codec', 'snappy')\n",
    "conf = conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:36:11.414333Z",
     "start_time": "2021-11-22T06:36:11.411207Z"
    }
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "appName=\"profiling nasabah TE channeling Uji Statistik\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:37:26.760501Z",
     "start_time": "2021-11-22T06:37:17.120226Z"
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.IllegalStateException: Spark context stopped while waiting for backend\n\tat org.apache.spark.scheduler.TaskSchedulerImpl.waitBackendReady(TaskSchedulerImpl.scala:835)\n\tat org.apache.spark.scheduler.TaskSchedulerImpl.postStartHook(TaskSchedulerImpl.scala:199)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:571)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-498d060b503e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.executor.memory'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'30g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.yarn.executor.memoryOverhead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.io.compression.codec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'snappy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0menableHiveSupport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6626826/lib/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6626826/lib/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6626826/lib/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[0;32m--> 123\u001b[0;31m                           conf, jsc, profiler_cls)\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6626826/lib/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Create the Java SparkContext through Py4J\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;31m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6626826/lib/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_initialize_context\u001b[0;34m(self, jconf)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mInitialize\u001b[0m \u001b[0mSparkContext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mallow\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0minitialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJavaSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6626826/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1525\u001b[0;31m             answer, self._gateway_client, None, self._fqn)\n\u001b[0m\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6626826/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.IllegalStateException: Spark context stopped while waiting for backend\n\tat org.apache.spark.scheduler.TaskSchedulerImpl.waitBackendReady(TaskSchedulerImpl.scala:835)\n\tat org.apache.spark.scheduler.TaskSchedulerImpl.postStartHook(TaskSchedulerImpl.scala:199)\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:571)\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:238)\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder.config(conf=conf) \\\n",
    "    .appName(appName) \\\n",
    "    .config('spark.dynamicAllocation.enabled', 'false') \\\n",
    "    .config(\"spark.blacklist.enabled\", 'false') \\\n",
    "    .config(\"spark.rpc.message.maxSize\", '256') \\\n",
    "    .config(\"spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation\",\"true\") \\\n",
    "    .config('spark.executor.instances', '5') \\\n",
    "    .config('spark.executor.cores', '9') \\\n",
    "    .config('spark.executor.memory', '30g') \\\n",
    "    .config('spark.yarn.executor.memoryOverhead', '10g') \\\n",
    "    .config('spark.io.compression.codec', 'snappy') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T06:36:17.259829Z",
     "start_time": "2021-11-22T06:36:17.250647Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-54754cda352c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# INPUT DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m df=spark.sql(\"\"\"\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# INPUT DATA\n",
    "df=spark.sql(\"\"\"\n",
    "\n",
    "\n",
    "select *  \n",
    "from dev_staging.dm_profilling_te_channel_detail\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T09:04:04.481368Z",
     "start_time": "2021-11-17T09:04:04.479215Z"
    }
   },
   "outputs": [],
   "source": [
    "import databricks.koalas as ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T09:04:20.733741Z",
     "start_time": "2021-11-17T09:04:15.994651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636829, 22)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdf= df.to_koalas()\n",
    "kdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T09:04:36.840231Z",
     "start_time": "2021-11-17T09:04:31.398315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_customer</th>\n",
       "      <th>jumlah_norek</th>\n",
       "      <th>TARGET_CUST</th>\n",
       "      <th>total_transaksi</th>\n",
       "      <th>status_kyc</th>\n",
       "      <th>source_kyc</th>\n",
       "      <th>status_rek</th>\n",
       "      <th>tgl_registrasi</th>\n",
       "      <th>tahun_registrasi</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>range_amount</th>\n",
       "      <th>total_berat</th>\n",
       "      <th>channel</th>\n",
       "      <th>agama</th>\n",
       "      <th>profesi</th>\n",
       "      <th>pendidikan</th>\n",
       "      <th>range_gaji</th>\n",
       "      <th>jenis_kelamin</th>\n",
       "      <th>range_usia</th>\n",
       "      <th>kanwil</th>\n",
       "      <th>segmentasi</th>\n",
       "      <th>rekomendasi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUSTOMER_SUDAH_KYC</td>\n",
       "      <td>1</td>\n",
       "      <td>280000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>PDS</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-24</td>\n",
       "      <td>2020</td>\n",
       "      <td>156261.9</td>\n",
       "      <td>&gt; Rp 100.000</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>SHOPEE</td>\n",
       "      <td>ISLAM</td>\n",
       "      <td>Ibu Rumah Tangga</td>\n",
       "      <td>SMA</td>\n",
       "      <td>&lt; 1 Juta</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>35-45</td>\n",
       "      <td>KANWIL BALIKPAPAN</td>\n",
       "      <td>Shopper</td>\n",
       "      <td>Not_Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUSTOMER_SUDAH_KYC</td>\n",
       "      <td>1</td>\n",
       "      <td>280000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>PDS</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>2020</td>\n",
       "      <td>67030.4</td>\n",
       "      <td>Rp 50.001 - Rp 100.000</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>SHOPEE</td>\n",
       "      <td>ISLAM</td>\n",
       "      <td>Lainnya</td>\n",
       "      <td>S1</td>\n",
       "      <td>3 - 5 Juta</td>\n",
       "      <td>Laki-laki</td>\n",
       "      <td>25-35</td>\n",
       "      <td>KANWIL BANDUNG</td>\n",
       "      <td>Uncertain</td>\n",
       "      <td>Not_Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUSTOMER_SUDAH_KYC</td>\n",
       "      <td>1</td>\n",
       "      <td>280000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PDS</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>2021</td>\n",
       "      <td>115137.8</td>\n",
       "      <td>&gt; Rp 100.000</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>SHOPEE</td>\n",
       "      <td>ISLAM</td>\n",
       "      <td>Profesional</td>\n",
       "      <td>S1</td>\n",
       "      <td>5 - 10 Juta</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>25-35</td>\n",
       "      <td>KANWIL SURABAYA</td>\n",
       "      <td>FirstTime</td>\n",
       "      <td>Low Cost Maintenance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUSTOMER_SUDAH_KYC</td>\n",
       "      <td>1</td>\n",
       "      <td>280000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PDS</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>2020</td>\n",
       "      <td>5061.5</td>\n",
       "      <td>&lt;Rp 10.000</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>SHOPEE</td>\n",
       "      <td>ISLAM</td>\n",
       "      <td>Lainnya</td>\n",
       "      <td>D1</td>\n",
       "      <td>3 - 5 Juta</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>25-35</td>\n",
       "      <td>KANWIL JAKARTA 2</td>\n",
       "      <td>Uncertain</td>\n",
       "      <td>Prepare to Lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUSTOMER_SUDAH_KYC</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>PDS</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-10</td>\n",
       "      <td>2020</td>\n",
       "      <td>1820380.0</td>\n",
       "      <td>&gt; Rp 100.000</td>\n",
       "      <td>2.0881</td>\n",
       "      <td>AGEN MITRA BUKALAPAK</td>\n",
       "      <td>ISLAM</td>\n",
       "      <td>Ibu Rumah Tangga</td>\n",
       "      <td>SMA</td>\n",
       "      <td>&lt; 1 Juta</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>25-35</td>\n",
       "      <td>KANTOR PUSAT</td>\n",
       "      <td>Shopper</td>\n",
       "      <td>Not_Churn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      status_customer  jumlah_norek  TARGET_CUST  total_transaksi status_kyc source_kyc status_rek tgl_registrasi  tahun_registrasi  total_amount            range_amount  total_berat               channel  agama           profesi pendidikan   range_gaji jenis_kelamin range_usia             kanwil segmentasi           rekomendasi\n",
       "0  CUSTOMER_SUDAH_KYC             1       280000                9          1        PDS          1     2020-10-24              2020      156261.9            > Rp 100.000       0.2130                SHOPEE  ISLAM  Ibu Rumah Tangga        SMA     < 1 Juta     Perempuan      35-45  KANWIL BALIKPAPAN    Shopper             Not_Churn\n",
       "1  CUSTOMER_SUDAH_KYC             1       280000                4          1        PDS          1     2020-10-07              2020       67030.4  Rp 50.001 - Rp 100.000       0.1066                SHOPEE  ISLAM           Lainnya         S1   3 - 5 Juta     Laki-laki      25-35     KANWIL BANDUNG  Uncertain             Not_Churn\n",
       "2  CUSTOMER_SUDAH_KYC             1       280000                1          1        PDS          1     2021-05-08              2021      115137.8            > Rp 100.000       0.1343                SHOPEE  ISLAM       Profesional         S1  5 - 10 Juta     Perempuan      25-35    KANWIL SURABAYA  FirstTime  Low Cost Maintenance\n",
       "3  CUSTOMER_SUDAH_KYC             1       280000                1          1        PDS          0     2020-10-26              2020        5061.5              <Rp 10.000       0.0159                SHOPEE  ISLAM           Lainnya         D1   3 - 5 Juta     Perempuan      25-35   KANWIL JAKARTA 2  Uncertain       Prepare to Lose\n",
       "4  CUSTOMER_SUDAH_KYC             1         5000                2          1        PDS          1     2020-11-10              2020     1820380.0            > Rp 100.000       2.0881  AGEN MITRA BUKALAPAK  ISLAM  Ibu Rumah Tangga        SMA     < 1 Juta     Perempuan      25-35       KANTOR PUSAT    Shopper             Not_Churn"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T09:05:06.428434Z",
     "start_time": "2021-11-17T09:04:45.275020Z"
    }
   },
   "outputs": [],
   "source": [
    "pdf=kdf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T09:05:07.186422Z",
     "start_time": "2021-11-17T09:05:06.430796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 636829 entries, 0 to 636828\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   status_customer   636829 non-null  object        \n",
      " 1   jumlah_norek      636829 non-null  int64         \n",
      " 2   TARGET_CUST       636674 non-null  float64       \n",
      " 3   total_transaksi   636829 non-null  int64         \n",
      " 4   status_kyc        528480 non-null  object        \n",
      " 5   source_kyc        213542 non-null  object        \n",
      " 6   status_rek        636822 non-null  object        \n",
      " 7   tgl_registrasi    636822 non-null  datetime64[ns]\n",
      " 8   tahun_registrasi  636822 non-null  float64       \n",
      " 9   total_amount      536931 non-null  float64       \n",
      " 10  range_amount      536931 non-null  object        \n",
      " 11  total_berat       536931 non-null  float64       \n",
      " 12  channel           415988 non-null  object        \n",
      " 13  agama             473164 non-null  object        \n",
      " 14  profesi           264605 non-null  object        \n",
      " 15  pendidikan        191617 non-null  object        \n",
      " 16  range_gaji        116506 non-null  object        \n",
      " 17  jenis_kelamin     533581 non-null  object        \n",
      " 18  range_usia        533572 non-null  object        \n",
      " 19  kanwil            533584 non-null  object        \n",
      " 20  segmentasi        498254 non-null  object        \n",
      " 21  rekomendasi       636829 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2), object(15)\n",
      "memory usage: 111.7+ MB\n"
     ]
    }
   ],
   "source": [
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T09:05:14.285515Z",
     "start_time": "2021-11-17T09:05:13.557380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 636829 entries, 0 to 636828\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   status_customer   636829 non-null  object        \n",
      " 1   jumlah_norek      636829 non-null  int64         \n",
      " 2   TARGET_CUST       636674 non-null  float64       \n",
      " 3   total_transaksi   636829 non-null  int64         \n",
      " 4   status_kyc        528480 non-null  object        \n",
      " 5   source_kyc        213542 non-null  object        \n",
      " 6   status_rek        636822 non-null  object        \n",
      " 7   tgl_registrasi    636822 non-null  datetime64[ns]\n",
      " 8   tahun_registrasi  636822 non-null  float64       \n",
      " 9   total_amount      536931 non-null  float64       \n",
      " 10  range_amount      536931 non-null  object        \n",
      " 11  total_berat       536931 non-null  float64       \n",
      " 12  channel           415988 non-null  object        \n",
      " 13  agama             473164 non-null  object        \n",
      " 14  profesi           264605 non-null  object        \n",
      " 15  pendidikan        191617 non-null  object        \n",
      " 16  range_gaji        116506 non-null  object        \n",
      " 17  jenis_kelamin     533581 non-null  object        \n",
      " 18  range_usia        533572 non-null  object        \n",
      " 19  kanwil            533584 non-null  object        \n",
      " 20  segmentasi        498254 non-null  object        \n",
      " 21  rekomendasi       636829 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2), object(15)\n",
      "memory usage: 111.7+ MB\n"
     ]
    }
   ],
   "source": [
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
